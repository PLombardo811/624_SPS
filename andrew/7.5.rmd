---
title: '7.5'
author: "Alejandro D. Osborne"
date: "April 24, 2019"
output: html_document
---
```{r}
library(AppliedPredictiveModeling)
library(caret)
library(nnet)
library(RANN)
library(ggplot2)
data(ChemicalManufacturingProcess)
```

Below we show all the steps we took to prepare our data for the various nonlinear models.  Steps included dividing the data into a training and test data set; pre-processing the data to transform, scale, center and impute values where they might be missing.  We also filtered the data to remove predictors which might be highly correlated with other predictors.  

```{r}
predictors <- subset(ChemicalManufacturingProcess,select= -Yield)
yield <- subset(ChemicalManufacturingProcess,select="Yield")
```

```{r}
set.seed(517)
trainingRows <- createDataPartition(yield$Yield,
p = 0.7,
list = FALSE)
```

```{r}
trainPredictors <- predictors[trainingRows,]
trainYield <- yield[trainingRows,]
```

```{r}
testPredictors <- predictors[-trainingRows,]
testYield <- yield[-trainingRows,]
```

```{r}
#Pre-process trainPredictors and apply to trainPredictors and testPredictors
pp <- preProcess(trainPredictors,method=c("BoxCox","center","scale","knnImpute"))
ppTrainPredictors <- predict(pp,trainPredictors)
ppTestPredictors <- predict(pp,testPredictors)
```

```{r}
#Identify and remove NZV
nzvpp = nearZeroVar(ppTrainPredictors)
ppTrainPredictors <- ppTrainPredictors[-nzvpp]
ppTestPredictors <- ppTestPredictors[-nzvpp]
```

```{r}
#Identify and remove highly correlated predictors
predcorr = cor(ppTrainPredictors)
```

```{r}
highCorrpp <- findCorrelation(predcorr)
ppTrainPredictors <- ppTrainPredictors[, -highCorrpp]
ppTestPredictors <- ppTestPredictors[, -highCorrpp]
```


a) We tested various nonlinear models including Neural Networks; Multivariate Adaptive Regression Splines (MARS); Support Vector Machines SVM; and K-Nearest Neighbor. Below we show all the code for training and testing those models.  

Based on the results of the model on the test data sets, the best performing models were the MARS model and the SVM model, depending on which test statistic you assessed. The MARS model had the lowest Root Mean Squared Error (1.28) and the SVM model had the highest R-squared value (0.58).  

#### Neural Networks  

```{r}
#Set-up trainControl
set.seed(517)
ctrl <- trainControl(method = "boot", number = 25)
```

```{r}
nnetAvgChemModel <- avNNet(x = ppTrainPredictors, y = trainYield,
size=5,
decay = 0.01,
linout=TRUE,
trace=FALSE,
maxit=500,
MaxNWts=5*(ncol(ppTrainPredictors)+1)+5+1)

nnetAvgPred1 <- predict(nnetAvgChemModel,ppTestPredictors)
nnetAvgValues1 <- data.frame(obs=testYield,pred=nnetAvgPred1)
defaultSummary(nnetAvgValues1)

#nnetChemModel <- nnet(x = ppTrainPredictors, y = trainYield,
#size=5,
#decay = 0.01,
#linout=TRUE,
#trace=FALSE,
#maxit=500,
#MaxNWts=5*(ncol(ppTrainPredictors)+1)+5+1)

nnetChemGrid <- expand.grid(.decay=c(0,0.01,0.1),.size=c(1:10),.bag=FALSE)

nnetChemTune <- train(x = ppTrainPredictors, y = trainYield,
method="avNNet",
tuneGrid=nnetChemGrid,
trcontrol=ctrl,
preProcess = c("center","scale"),
linout=TRUE,
trace=FALSE,
maxit=500,
MaxNWts=10*(ncol(ppTrainPredictors)+1)+10+1)

nnetPred1 <- predict(nnetChemTune,ppTestPredictors)
nnetValues1 <- data.frame(obs=testYield,pred=nnetPred1)
defaultSummary(nnetValues1)

```

#### Multivariate Adaptive Regression Splines  

```{r}
set.seed(614)

marsChemGrid <- expand.grid(degree = c(1:2), nprune = c(2:10))
marsChemTune <- train(x = ppTrainPredictors, y = trainYield,
method = "earth",
trControl = ctrl,
tuneGrid = marsChemGrid)

MarsPred1 <- predict(marsChemTune,ppTestPredictors)
MarsValues1 <- data.frame(obs=testYield,pred=MarsPred1)
colnames(MarsValues1)[2] <- "pred"
defaultSummary(MarsValues1)

```

#### Support Vector Machines  

```{r}
psvmTuneGrid <- expand.grid(C=c(0.01,0.05,0.1), degree=c(1,2), scale=c(0.25,0.5,1))
PSVMChemTune <- train(x = ppTrainPredictors, y = trainYield,
method = "svmPoly",
trControl = ctrl,
tuneGrid = psvmTuneGrid)

PSVMPred1 <- predict(PSVMChemTune,ppTestPredictors)
PSVMValues1 <- data.frame(obs=testYield,pred=PSVMPred1)
defaultSummary(PSVMValues1)
PSVMChemTune$finalModel

```

#### K-Nearest Neighbor  

```{r}
knnChemModel <- train(x = ppTrainPredictors, y = trainYield,
method = "knn",
preProcess = c("center","scale"),
trControl = ctrl,
tuneLength=20)

knnPred1 <- predict(knnChemModel,ppTestPredictors)
knnValues1 <- data.frame(obs=testYield,pred=knnPred1)
defaultSummary(knnValues1)

```

(b) Since the SVM models do not allow us to assess the most important predictors, we focused our analysis on the MARS model. The optimal degree and number of terms that maximize R2 for the MARS model are 1 and 3, respectively, with an R2 of 0.51.  The top two MARS predictors are ManufacturingProcess32 and ManufacturingProcess09, are the same as the top predictors for the top performing linear (PLS) model.  

The final MARS model has slightly worse cross-validation and test set performance than the optimal PLS model. This suggests the underlying structure between the predictors and the response is approximately linear.  PLS identifies additional predictive information from the other predictors that improve the predictive ability of the models.  Overall, many of the manufacturing process predictors are at the top of the importance list.  

```{r}
marsChemTune$results$degree[best(marsChemTune$results, "Rsquared", maximize = TRUE)]
```

```{r}
marsChemTune$results$nprune[best(marsChemTune$results, "Rsquared", maximize = TRUE)]
```

```{r}
round(marsChemTune$results$Rsquared[best(marsChemTune$results, "Rsquared", maximize = TRUE)],2)
```

```{r}
chemMARSSummary <- summary(marsChemTune$finalModel)
chemMARSSummary
```

```{r}
varImp(marsChemTune)
```

c) Below we plot the best performing predictor variables (ManufacturingProcess32 and ManufacturingProcess09) against the dependent variable (Yield.) In both cases it looks like there is a clear positive trend between each process predictor variable and the dependent variable - in other words the higher the process value the stronger the yield.  

```{r}

ggplot(ChemicalManufacturingProcess, aes(x=ManufacturingProcess32, y=Yield)) +  geom_point(shape=1) + geom_smooth(se=TRUE)

ggplot(ChemicalManufacturingProcess, aes(x=ManufacturingProcess32, y=Yield)) +  geom_point(shape=1) + geom_smooth(method = lm, se=TRUE)

```
```{r}

ggplot(ChemicalManufacturingProcess, aes(x=ManufacturingProcess09, y=Yield)) +  geom_point(shape=1) + geom_smooth(se=TRUE)

ggplot(ChemicalManufacturingProcess, aes(x=ManufacturingProcess09, y=Yield)) +  geom_point(shape=1) + geom_smooth(method = lm, se=TRUE)

```
